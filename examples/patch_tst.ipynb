{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ntA8BBFtUY7"
      },
      "source": [
        "# Patch Time Series Transformer in HuggingFace - Getting Started\n",
        "\n",
        "In this blog, we provide examples of how to get started with PatchTST. We first demonstrate the forecasting capability of `PatchTST` on the Electricity data. We will then demonstrate the transfer learning capability of `PatchTST` by using the previously trained model to do zero-shot forecasting on the electrical transformer (ETTh1) dataset. The zero-shot forecasting performance will denote the `test` performance of the model in the `target` domain, without any  training on the target domain. Subsequently, we will do linear probing and (then) finetuning of the pretrained model on the `train` part of the target data and will validate the forecasting performance on the `test` part of the target data.\n",
        "\n",
        "The `PatchTST` model was proposed in A Time Series is Worth [64 Words: Long-term Forecasting with Transformers](https://huggingface.co/papers/2211.14730) by Yuqi Nie, Nam H. Nguyen, Phanwadee Sinthong, Jayant Kalagnanam and presented at ICLR 2023.\n",
        "\n",
        "\n",
        "## Quick overview of PatchTST\n",
        "\n",
        "At a high level, the model vectorizes individual time series in a batch into patches of a given size and encodes the resulting sequence of vectors via a Transformer that then outputs the prediction length forecast via an appropriate head.\n",
        "\n",
        "The model is based on two key components:\n",
        "  1. segmentation of time series into subseries-level patches which serve as input tokens to the Transformer;\n",
        "  2.  channel-independence where each channel contains a single univariate time series that shares the same embedding and Transformer weights across all the series, i.e. a [global](https://doi.org/10.1016/j.ijforecast.2021.03.004) univariate model.\n",
        "\n",
        "The patching design naturally has three-fold benefit:\n",
        " - local semantic information is retained in the embedding;\n",
        " - computation and memory usage of the attention maps are quadratically reduced given the same look-back window via strides between patches; and\n",
        " - the model can attend longer history via a trade-off between the patch length (input vector size) and the context length (number of sequences).\n",
        "\n",
        "\n",
        "In addition, `PatchTST` has a modular design to seamlessly support masked time series pre-training as well as direct time series forecasting.\n",
        "\n",
        "| ![PatchTST model schematics](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/patchtst/patchtst-arch.png) |\n",
        "|:--:|\n",
        "|(a) `PatchTST` model overview where a batch of \\\\(M\\\\) time series each of length \\\\(L\\\\) are processed independently (by reshaping them into the batch dimension) via a Transformer backbone and then reshaping the resulting batch back into \\\\(M \\\\) series of prediction length \\\\(T\\\\). Each *univariate* series can be processed in a supervised fashion (b) where the patched set of vectors is used to output the full prediction length or in a self-supervised fashion (c) where masked patches are predicted. |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTkKab0btUY8"
      },
      "source": [
        "# Installation\n",
        "\n",
        "This demo requires Hugging Face [`Transformers`](https://github.com/huggingface/transformers) for the model, and the IBM `tsfm` package for auxiliary data pre-processing.\n",
        "We can install both by cloning the `tsfm` repository and following the below steps.\n",
        "\n",
        "1. Clone the public IBM Time Series Foundation Model Repository [`tsfm`](https://github.com/ibm/tsfm).\n",
        "    ```bash\n",
        "    pip install git+https://github.com/IBM/tsfm.git\n",
        "    ```\n",
        "2. Install Hugging Face [`Transformers`](https://github.com/huggingface/transformers#installation)\n",
        "    ```bash\n",
        "    pip install transformers\n",
        "    ```\n",
        "3. Test it with the following commands in a `python` terminal.\n",
        "    ```python\n",
        "    from transformers import PatchTSTConfig\n",
        "    from tsfm_public.toolkit.dataset import ForecastDFDataset\n",
        "    ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzQnV-JUtUY8"
      },
      "source": [
        "## Part 1: Forecasting on the Electricity dataset\n",
        "Here we train a `PatchTST` model directly on the Electricity dataset (available from https://github.com/zhouhaoyi/Informer2020), and evaluate its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qvW0BySJtUY8"
      },
      "outputs": [],
      "source": [
        "# Standard\n",
        "import os\n",
        "\n",
        "# Third Party\n",
        "from transformers import (\n",
        "    EarlyStoppingCallback,\n",
        "    PatchTSTConfig,\n",
        "    PatchTSTForPrediction,\n",
        "    set_seed,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# First Party\n",
        "from tsfm_public.toolkit.dataset import ForecastDFDataset\n",
        "from tsfm_public.toolkit.time_series_preprocessor import TimeSeriesPreprocessor\n",
        "from tsfm_public.toolkit.util import select_by_index\n",
        "\n",
        "# supress some warnings\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", module=\"torch\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M4Xaq0ctUY9"
      },
      "source": [
        " ### Set seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NsLekIy6tUY9"
      },
      "outputs": [],
      "source": [
        "set_seed(2023)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkUHEiSNtUY9"
      },
      "source": [
        "### Load and prepare datasets\n",
        "\n",
        " In the next cell, please adjust the following parameters to suit your application:\n",
        " - `dataset_path`: path to local .csv file, or web address to a csv file for the data of interest. Data is loaded with pandas, so anything supported by\n",
        "   `pd.read_csv` is supported: (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html).\n",
        " - `timestamp_column`: column name containing timestamp information, use `None` if there is no such column.\n",
        " - `id_columns`: List of column names specifying the IDs of different time series. If no ID column exists, use `[]`.\n",
        " - `forecast_columns`: List of columns to be modeled\n",
        " - `context_length`: The amount of historical data used as input to the model. Windows of the input time series data with length equal to `context_length` will be extracted from the input dataframe. In the case of a multi-time series dataset, the context windows will be created so that they are contained within a single time series (i.e., a single ID).\n",
        " - `forecast_horizon`: Number of timestamps to forecast in the future.\n",
        " - `train_start_index`, `train_end_index`: the start and end indices in the loaded data which delineate the training data.\n",
        " - `valid_start_index`, `eval_end_index`: the start and end indices in the loaded data which delineate the validation data.\n",
        " - `test_start_index`, `eval_end_index`: the start and end indices in the loaded data which delineate the test data.\n",
        " - `patch_length`: The patch length for the `PatchTST` model. It is recommended to choose a value that evenly divides `context_length`.\n",
        " - `num_workers`: Number of CPU workers in the PyTorch dataloader.\n",
        " - `batch_size`: Batch size.\n",
        "\n",
        "The data is first loaded into a Pandas dataframe and split into training, validation, and test parts. Then the Pandas dataframes are converted to the appropriate PyTorch dataset required for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mociR5p8tUY9"
      },
      "outputs": [],
      "source": [
        "# The ECL data is available from https://github.com/zhouhaoyi/Informer2020?tab=readme-ov-file#data\n",
        "dataset_path = \"./sample_data/ECL.csv\"\n",
        "timestamp_column = \"date\"\n",
        "id_columns = []\n",
        "\n",
        "# data = pd.read_csv(\n",
        "#     dataset_path,\n",
        "#     parse_dates=[timestamp_column],\n",
        "# )\n",
        "# display(data.head())\n",
        "\n",
        "context_length = 512\n",
        "forecast_horizon = 96\n",
        "patch_length = 16\n",
        "num_workers = 16  # Reduce this if you have low number of CPU cores\n",
        "batch_size = 64  # Adjust according to GPU memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "3FzeZ2YftUY9",
        "outputId": "006654ce-5a61-4559-d36a-db0e3b64e936"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                 date  MT_000  MT_001  MT_002  MT_003  MT_004  MT_005  MT_006  \\\n",
              "0 2012-01-01 00:00:00    14.0    69.0   234.0   415.0   215.0  1056.0    29.0   \n",
              "1 2012-01-01 01:00:00    18.0    92.0   312.0   556.0   292.0  1363.0    29.0   \n",
              "2 2012-01-01 02:00:00    21.0    96.0   312.0   560.0   272.0  1240.0    29.0   \n",
              "3 2012-01-01 03:00:00    20.0    92.0   312.0   443.0   213.0   845.0    24.0   \n",
              "4 2012-01-01 04:00:00    22.0    91.0   312.0   346.0   190.0   647.0    16.0   \n",
              "\n",
              "   MT_007  MT_008  ...  MT_311  MT_312   MT_313  MT_314  MT_315  MT_316  \\\n",
              "0   840.0   226.0  ...   676.0   372.0  80100.0  4719.0  5002.0    48.0   \n",
              "1  1102.0   271.0  ...   805.0   452.0  95200.0  4643.0  6617.0    65.0   \n",
              "2  1025.0   270.0  ...   817.0   430.0  96600.0  4285.0  6571.0    64.0   \n",
              "3   833.0   179.0  ...   801.0   291.0  94500.0  4222.0  6365.0    65.0   \n",
              "4   733.0   186.0  ...   807.0   279.0  91300.0  4116.0  6298.0    75.0   \n",
              "\n",
              "   MT_317  MT_318  MT_319  MT_320  \n",
              "0    38.0  1558.0   182.0  2162.0  \n",
              "1    47.0  2177.0   253.0  2835.0  \n",
              "2    43.0  2193.0   218.0  2764.0  \n",
              "3    39.0  1315.0   195.0  2735.0  \n",
              "4    40.0  1378.0   191.0  2721.0  \n",
              "\n",
              "[5 rows x 322 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4bcc2052-e6de-4890-8a5e-b816426fbd9d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>MT_000</th>\n",
              "      <th>MT_001</th>\n",
              "      <th>MT_002</th>\n",
              "      <th>MT_003</th>\n",
              "      <th>MT_004</th>\n",
              "      <th>MT_005</th>\n",
              "      <th>MT_006</th>\n",
              "      <th>MT_007</th>\n",
              "      <th>MT_008</th>\n",
              "      <th>...</th>\n",
              "      <th>MT_311</th>\n",
              "      <th>MT_312</th>\n",
              "      <th>MT_313</th>\n",
              "      <th>MT_314</th>\n",
              "      <th>MT_315</th>\n",
              "      <th>MT_316</th>\n",
              "      <th>MT_317</th>\n",
              "      <th>MT_318</th>\n",
              "      <th>MT_319</th>\n",
              "      <th>MT_320</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-01-01 00:00:00</td>\n",
              "      <td>14.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>415.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>1056.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>840.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>...</td>\n",
              "      <td>676.0</td>\n",
              "      <td>372.0</td>\n",
              "      <td>80100.0</td>\n",
              "      <td>4719.0</td>\n",
              "      <td>5002.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1558.0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>2162.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-01-01 01:00:00</td>\n",
              "      <td>18.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>556.0</td>\n",
              "      <td>292.0</td>\n",
              "      <td>1363.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1102.0</td>\n",
              "      <td>271.0</td>\n",
              "      <td>...</td>\n",
              "      <td>805.0</td>\n",
              "      <td>452.0</td>\n",
              "      <td>95200.0</td>\n",
              "      <td>4643.0</td>\n",
              "      <td>6617.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>2177.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>2835.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-01-01 02:00:00</td>\n",
              "      <td>21.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>272.0</td>\n",
              "      <td>1240.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1025.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>...</td>\n",
              "      <td>817.0</td>\n",
              "      <td>430.0</td>\n",
              "      <td>96600.0</td>\n",
              "      <td>4285.0</td>\n",
              "      <td>6571.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>2193.0</td>\n",
              "      <td>218.0</td>\n",
              "      <td>2764.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-01-01 03:00:00</td>\n",
              "      <td>20.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>443.0</td>\n",
              "      <td>213.0</td>\n",
              "      <td>845.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>833.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>...</td>\n",
              "      <td>801.0</td>\n",
              "      <td>291.0</td>\n",
              "      <td>94500.0</td>\n",
              "      <td>4222.0</td>\n",
              "      <td>6365.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1315.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>2735.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-01-01 04:00:00</td>\n",
              "      <td>22.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>346.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>647.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>733.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>...</td>\n",
              "      <td>807.0</td>\n",
              "      <td>279.0</td>\n",
              "      <td>91300.0</td>\n",
              "      <td>4116.0</td>\n",
              "      <td>6298.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1378.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>2721.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 322 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bcc2052-e6de-4890-8a5e-b816426fbd9d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4bcc2052-e6de-4890-8a5e-b816426fbd9d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4bcc2052-e6de-4890-8a5e-b816426fbd9d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e7601308-d351-44b9-b3ba-f848c9689f5a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e7601308-d351-44b9-b3ba-f848c9689f5a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e7601308-d351-44b9-b3ba-f848c9689f5a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "data = pd.read_csv(\n",
        "    dataset_path,\n",
        "    parse_dates=[timestamp_column],\n",
        ")\n",
        "display(data.head())\n",
        "forecast_columns = list(data.columns[1:])\n",
        "\n",
        "# get split\n",
        "num_train = int(len(data) * 0.7)\n",
        "num_test = int(len(data) * 0.2)\n",
        "num_valid = len(data) - num_train - num_test\n",
        "border1s = [\n",
        "    0,\n",
        "    num_train - context_length,\n",
        "    len(data) - num_test - context_length,\n",
        "]\n",
        "border2s = [num_train, num_train + num_valid, len(data)]\n",
        "\n",
        "train_start_index = border1s[0]  # None indicates beginning of dataset\n",
        "train_end_index = border2s[0]\n",
        "\n",
        "# we shift the start of the evaluation period back by context length so that\n",
        "# the first evaluation timestamp is immediately following the training data\n",
        "valid_start_index = border1s[1]\n",
        "valid_end_index = border2s[1]\n",
        "\n",
        "test_start_index = border1s[2]\n",
        "test_end_index = border2s[2]\n",
        "\n",
        "train_data = select_by_index(\n",
        "    data,\n",
        "    id_columns=id_columns,\n",
        "    start_index=train_start_index,\n",
        "    end_index=train_end_index,\n",
        ")\n",
        "valid_data = select_by_index(\n",
        "    data,\n",
        "    id_columns=id_columns,\n",
        "    start_index=valid_start_index,\n",
        "    end_index=valid_end_index,\n",
        ")\n",
        "test_data = select_by_index(\n",
        "    data,\n",
        "    id_columns=id_columns,\n",
        "    start_index=test_start_index,\n",
        "    end_index=test_end_index,\n",
        ")\n",
        "\n",
        "time_series_preprocessor = TimeSeriesPreprocessor(\n",
        "    timestamp_column=timestamp_column,\n",
        "    id_columns=id_columns,\n",
        "    input_columns=forecast_columns,\n",
        "    output_columns=forecast_columns,\n",
        "    scaling=True,\n",
        ")\n",
        "time_series_preprocessor = time_series_preprocessor.train(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhfdQkYStUY-",
        "outputId": "4b230c62-39ea-4fb5-c233-4ccaedeb1865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tsfm_public/toolkit/dataset.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[\"group\"] = 0  # create a artificial group\n",
            "/usr/local/lib/python3.11/dist-packages/tsfm_public/toolkit/dataset.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[\"group\"] = 0  # create a artificial group\n",
            "/usr/local/lib/python3.11/dist-packages/tsfm_public/toolkit/dataset.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data_df[\"group\"] = 0  # create a artificial group\n"
          ]
        }
      ],
      "source": [
        "train_dataset = ForecastDFDataset(\n",
        "    time_series_preprocessor.preprocess(train_data),\n",
        "    id_columns=id_columns,\n",
        "    timestamp_column=\"date\",\n",
        "    # input_columns=forecast_columns,\n",
        "    # output_columns=forecast_columns,\n",
        "    target_columns=forecast_columns,\n",
        "    context_length=context_length,\n",
        "    prediction_length=forecast_horizon,\n",
        ")\n",
        "valid_dataset = ForecastDFDataset(\n",
        "    time_series_preprocessor.preprocess(valid_data),\n",
        "    id_columns=id_columns,\n",
        "    timestamp_column=\"date\",\n",
        "    # input_columns=forecast_columns,\n",
        "    # output_columns=forecast_columns,\n",
        "    target_columns=forecast_columns,\n",
        "    context_length=context_length,\n",
        "    prediction_length=forecast_horizon,\n",
        ")\n",
        "test_dataset = ForecastDFDataset(\n",
        "    time_series_preprocessor.preprocess(test_data),\n",
        "    id_columns=id_columns,\n",
        "    timestamp_column=\"date\",\n",
        "    # input_columns=forecast_columns,\n",
        "    # output_columns=forecast_columns,\n",
        "    target_columns=forecast_columns,\n",
        "    context_length=context_length,\n",
        "    prediction_length=forecast_horizon,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW3DuzRqtUY-"
      },
      "source": [
        "### Configure the PatchTST model\n",
        "\n",
        "Next, we instantiate a randomly initialized `PatchTST` model with a configuration. The settings below control the different hyperparameters related to the architecture.\n",
        "  - `num_input_channels`: the number of input channels (or dimensions) in the time series data. This is\n",
        "    automatically set to the number for forecast columns.\n",
        "  - `context_length`: As described above, the amount of historical data used as input to the model.\n",
        "  - `patch_length`: The length of the patches extracted from the context window (of length `context_length`).\n",
        "  - `patch_stride`: The stride used when extracting patches from the context window.\n",
        "  - `random_mask_ratio`: The fraction of input patches that are completely masked for pretraining the model.\n",
        "  - `d_model`: Dimension of the transformer layers.\n",
        "  - `num_attention_heads`: The number of attention heads for each attention layer in the Transformer encoder.\n",
        "  - `num_hidden_layers`: The number of encoder layers.\n",
        "  - `ffn_dim`: Dimension of the intermediate (often referred to as feed-forward) layer in the encoder.\n",
        "  - `dropout`: Dropout probability for all fully connected layers in the encoder.\n",
        "  - `head_dropout`: Dropout probability used in the head of the model.\n",
        "  - `pooling_type`: Pooling of the embedding. `\"mean\"`, `\"max\"` and `None` are supported.\n",
        "  - `channel_attention`: Activate the channel attention block in the Transformer to allow channels to attend to each other.\n",
        "  - `scaling`: Whether to scale the input targets via \"mean\" scaler, \"std\" scaler, or no scaler if `None`. If `True`, the\n",
        "    scaler is set to `\"mean\"`.\n",
        "  - `loss`: The loss function for the model corresponding to the `distribution_output` head. For parametric\n",
        "    distributions it is the negative log-likelihood (`\"nll\"`) and for point estimates it is the mean squared\n",
        "    error `\"mse\"`.\n",
        "  - `pre_norm`: Normalization is applied before self-attention if pre_norm is set to `True`. Otherwise, normalization is\n",
        "    applied after residual block.\n",
        "  - `norm_type`: Normalization at each Transformer layer. Can be `\"BatchNorm\"` or `\"LayerNorm\"`.\n",
        "\n",
        "For full details on the parameters, we refer to the [documentation](https://huggingface.co/docs/transformers/main/en/model_doc/patchtst#transformers.PatchTSTConfig).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7wI-EThtUY-"
      },
      "outputs": [],
      "source": [
        "config = PatchTSTConfig(\n",
        "    num_input_channels=len(forecast_columns),\n",
        "    context_length=context_length,\n",
        "    patch_length=patch_length,\n",
        "    patch_stride=patch_length,\n",
        "    prediction_length=forecast_horizon,\n",
        "    random_mask_ratio=0.4,\n",
        "    d_model=128,\n",
        "    num_attention_heads=16,\n",
        "    num_hidden_layers=3,\n",
        "    ffn_dim=256,\n",
        "    dropout=0.2,\n",
        "    head_dropout=0.2,\n",
        "    pooling_type=None,\n",
        "    channel_attention=False,\n",
        "    scaling=\"std\",\n",
        "    loss=\"mse\",\n",
        "    pre_norm=True,\n",
        "    norm_type=\"batchnorm\",\n",
        ")\n",
        "model = PatchTSTForPrediction(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUMSUNHrtUY-"
      },
      "source": [
        "### Train model\n",
        "\n",
        "Next, we can leverage the Hugging Face [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) class to train the model based on the direct forecasting strategy. We first define the [TrainingArguments](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments) which lists various hyperparameters for training such as the number of epochs, learning rate and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tyvf_ZdjtUY-"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./checkpoint/patchtst/electricity/pretrain/output/\",\n",
        "    overwrite_output_dir=True,\n",
        "    # learning_rate=0.001,\n",
        "    num_train_epochs=100,\n",
        "    do_eval=True,\n",
        "    eval_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    dataloader_num_workers=num_workers,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_total_limit=3,\n",
        "    logging_dir=\"./checkpoint/patchtst/electricity/pretrain/logs/\",  # Make sure to specify a logging directory\n",
        "    load_best_model_at_end=True,  # Load the best model when training ends\n",
        "    metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
        "    greater_is_better=False,  # For loss\n",
        "    label_names=[\"future_values\"],\n",
        ")\n",
        "\n",
        "# Create the early stopping callback\n",
        "early_stopping_callback = EarlyStoppingCallback(\n",
        "    early_stopping_patience=10,  # Number of epochs with no improvement after which to stop\n",
        "    early_stopping_threshold=0.0001,  # Minimum improvement required to consider as improvement\n",
        ")\n",
        "\n",
        "# define trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    callbacks=[early_stopping_callback],\n",
        "    # compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# pretrain\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7m3e0w5tUY-"
      },
      "source": [
        "### Evaluate the model on the test set of the source domain\n",
        "\n",
        "Next, we can leverage `trainer.evaluate()` to calculate test metrics. While this is not the target metric to judge in this task, it provides a reasonable check that the pretrained model has trained properly.\n",
        "Note that the training and evaluation loss for `PatchTST` is the Mean Squared Error (MSE) loss. Hence, we do not separately compute the MSE metric in any of the following evaluation experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVI935DTtUY-"
      },
      "outputs": [],
      "source": [
        "results = trainer.evaluate(test_dataset)\n",
        "print(\"Test result:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWmCe_yntUY-"
      },
      "source": [
        "The MSE of `0.131` is very close to the value reported for the Electricity dataset in the original `PatchTST` paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liZZ3XJLtUY-"
      },
      "source": [
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utw-zz-ktUY-"
      },
      "outputs": [],
      "source": [
        "save_dir = \"patchtst/electricity/model/pretrain/\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "trainer.save_model(save_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phNa1mM_tUY-"
      },
      "source": [
        "## Part 2: Transfer Learning from Electricity to ETTh1\n",
        "\n",
        "\n",
        "In this section, we will demonstrate the transfer learning capability of the `PatchTST` model.\n",
        "We use the model pre-trained on the Electricity dataset to do zero-shot forecasting on the ETTh1 dataset.\n",
        "\n",
        "\n",
        "By Transfer Learning, we mean that we first pretrain the model for a forecasting task on a `source` dataset (which we did above on the `Electricity` dataset). Then, we will use the pretrained model for zero-shot forecasting on a `target` dataset. By zero-shot, we mean that we test the performance in the `target` domain without any additional training. We hope that the model gained enough knowledge from pretraining which can be transferred to a different dataset.\n",
        "Subsequently, we will do linear probing and (then) finetuning of the pretrained model on the `train` split of the target data and will validate the forecasting performance on the `test` split of the target data. In this example, the source dataset is the `Electricity` dataset and the target dataset is ETTh1.\n",
        "\n",
        "### Transfer learning on ETTh1 data.\n",
        "All evaluations are on the `test` part of the `ETTh1` data.\n",
        "\n",
        "Step 1: Directly evaluate the electricity-pretrained model. This is the zero-shot performance.\n",
        "\n",
        "Step 2: Evaluate after doing linear probing.\n",
        "\n",
        "Step 3: Evaluate after doing full finetuning.\n",
        "\n",
        "### Load ETTh dataset\n",
        "\n",
        "Below, we load the `ETTh1` dataset as a Pandas dataframe. Next, we create 3 splits for training, validation, and testing. We then leverage the `TimeSeriesPreprocessor` class to prepare each split for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYb2TQ9PtUY-"
      },
      "outputs": [],
      "source": [
        "dataset = \"ETTh1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlDzbOwXtUY-"
      },
      "outputs": [],
      "source": [
        "print(f\"Loading target dataset: {dataset}\")\n",
        "dataset_path = f\"https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/{dataset}.csv\"\n",
        "timestamp_column = \"date\"\n",
        "id_columns = []\n",
        "forecast_columns = [\"HUFL\", \"HULL\", \"MUFL\", \"MULL\", \"LUFL\", \"LULL\", \"OT\"]\n",
        "train_start_index = None  # None indicates beginning of dataset\n",
        "train_end_index = 12 * 30 * 24\n",
        "\n",
        "# we shift the start of the evaluation period back by context length so that\n",
        "# the first evaluation timestamp is immediately following the training data\n",
        "valid_start_index = 12 * 30 * 24 - context_length\n",
        "valid_end_index = 12 * 30 * 24 + 4 * 30 * 24\n",
        "\n",
        "test_start_index = 12 * 30 * 24 + 4 * 30 * 24 - context_length\n",
        "test_end_index = 12 * 30 * 24 + 8 * 30 * 24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r78V8hRutUY-"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\n",
        "    dataset_path,\n",
        "    parse_dates=[timestamp_column],\n",
        ")\n",
        "\n",
        "train_data = select_by_index(\n",
        "    data,\n",
        "    id_columns=id_columns,\n",
        "    start_index=train_start_index,\n",
        "    end_index=train_end_index,\n",
        ")\n",
        "valid_data = select_by_index(\n",
        "    data,\n",
        "    id_columns=id_columns,\n",
        "    start_index=valid_start_index,\n",
        "    end_index=valid_end_index,\n",
        ")\n",
        "test_data = select_by_index(\n",
        "    data,\n",
        "    id_columns=id_columns,\n",
        "    start_index=test_start_index,\n",
        "    end_index=test_end_index,\n",
        ")\n",
        "\n",
        "time_series_preprocessor = TimeSeriesPreprocessor(\n",
        "    timestamp_column=timestamp_column,\n",
        "    id_columns=id_columns,\n",
        "    input_columns=forecast_columns,\n",
        "    output_columns=forecast_columns,\n",
        "    scaling=True,\n",
        ")\n",
        "time_series_preprocessor = time_series_preprocessor.train(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7wxBlsntUY-"
      },
      "outputs": [],
      "source": [
        "train_dataset = ForecastDFDataset(\n",
        "    time_series_preprocessor.preprocess(train_data),\n",
        "    id_columns=id_columns,\n",
        "    input_columns=forecast_columns,\n",
        "    output_columns=forecast_columns,\n",
        "    context_length=context_length,\n",
        "    prediction_length=forecast_horizon,\n",
        ")\n",
        "valid_dataset = ForecastDFDataset(\n",
        "    time_series_preprocessor.preprocess(valid_data),\n",
        "    id_columns=id_columns,\n",
        "    input_columns=forecast_columns,\n",
        "    output_columns=forecast_columns,\n",
        "    context_length=context_length,\n",
        "    prediction_length=forecast_horizon,\n",
        ")\n",
        "test_dataset = ForecastDFDataset(\n",
        "    time_series_preprocessor.preprocess(test_data),\n",
        "    id_columns=id_columns,\n",
        "    input_columns=forecast_columns,\n",
        "    output_columns=forecast_columns,\n",
        "    context_length=context_length,\n",
        "    prediction_length=forecast_horizon,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztgbERCOtUY-"
      },
      "source": [
        "### Zero-shot forecasting on ETTH\n",
        "\n",
        "As we are going to test forecasting performance out-of-the-box, we load the model which we pretrained above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kUBBpAItUY-"
      },
      "outputs": [],
      "source": [
        "finetune_forecast_model = PatchTSTForPrediction.from_pretrained(\n",
        "    \"patchtst/electricity/model/pretrain/\",\n",
        "    num_input_channels=len(forecast_columns),\n",
        "    head_dropout=0.7,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC6CQhr0tUY-"
      },
      "outputs": [],
      "source": [
        "finetune_forecast_args = TrainingArguments(\n",
        "    output_dir=\"./checkpoint/patchtst/transfer/finetune/output/\",\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=0.0001,\n",
        "    num_train_epochs=100,\n",
        "    do_eval=True,\n",
        "    eval_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    dataloader_num_workers=num_workers,\n",
        "    report_to=\"tensorboard\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_total_limit=3,\n",
        "    logging_dir=\"./checkpoint/patchtst/transfer/finetune/logs/\",  # Make sure to specify a logging directory\n",
        "    load_best_model_at_end=True,  # Load the best model when training ends\n",
        "    metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
        "    greater_is_better=False,  # For loss\n",
        "    label_names=[\"future_values\"],\n",
        ")\n",
        "\n",
        "# Create a new early stopping callback with faster convergence properties\n",
        "early_stopping_callback = EarlyStoppingCallback(\n",
        "    early_stopping_patience=10,  # Number of epochs with no improvement after which to stop\n",
        "    early_stopping_threshold=0.001,  # Minimum improvement required to consider as improvement\n",
        ")\n",
        "\n",
        "finetune_forecast_trainer = Trainer(\n",
        "    model=finetune_forecast_model,\n",
        "    args=finetune_forecast_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    callbacks=[early_stopping_callback],\n",
        ")\n",
        "\n",
        "print(\"\\n\\nDoing zero-shot forecasting on target data\")\n",
        "result = finetune_forecast_trainer.evaluate(test_dataset)\n",
        "print(\"Target data zero-shot forecasting result:\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83ugS2BstUY-"
      },
      "source": [
        "As can be seen, with a zero-shot forecasting approach we obtain an MSE of 0.370 which is near to the state-of-the-art result in the original `PatchTST` paper.\n",
        "\n",
        "Next, let's see how we can do by performing linear probing, which involves training a linear layer on top of a frozen pre-trained model. Linear probing is often done to test the performance of features of a pretrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSLpWd97tUY-"
      },
      "source": [
        "### Linear probing on ETTh1\n",
        "\n",
        "We can do a quick linear probing on the `train` part of the target data to see any possible `test` performance improvement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5BPo-pftUY-"
      },
      "outputs": [],
      "source": [
        "# Freeze the backbone of the model\n",
        "for param in finetune_forecast_trainer.model.model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "print(\"\\n\\nLinear probing on the target data\")\n",
        "finetune_forecast_trainer.train()\n",
        "print(\"Evaluating\")\n",
        "result = finetune_forecast_trainer.evaluate(test_dataset)\n",
        "print(\"Target data head/linear probing result:\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7p2g1RrtUY_"
      },
      "source": [
        "As can be seen, by only training a simple linear layer on top of the frozen backbone, the MSE decreased from 0.370 to 0.357, beating the originally reported results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voVp0uHutUY_"
      },
      "outputs": [],
      "source": [
        "save_dir = f\"patchtst/electricity/model/transfer/{dataset}/model/linear_probe/\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "finetune_forecast_trainer.save_model(save_dir)\n",
        "\n",
        "save_dir = f\"patchtst/electricity/model/transfer/{dataset}/preprocessor/\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "time_series_preprocessor.save_pretrained(save_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv60_y44tUY_"
      },
      "source": [
        "Finally, let's see if we can get additional improvements by doing a full fine-tune of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au-bkLjEtUY_"
      },
      "source": [
        "### Full fine-tune on ETTh1\n",
        "\n",
        "We can do a full model fine-tune (instead of probing the last linear layer as shown above) on the `train` part of the target data to see a possible `test` performance improvement. The code looks similar to the linear probing task above, except that we are not freezing any parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNkAZdSCtUY_"
      },
      "outputs": [],
      "source": [
        "# Reload the model\n",
        "finetune_forecast_model = PatchTSTForPrediction.from_pretrained(\n",
        "    \"patchtst/electricity/model/pretrain/\",\n",
        "    num_input_channels=len(forecast_columns),\n",
        "    dropout=0.7,\n",
        "    head_dropout=0.7,\n",
        ")\n",
        "finetune_forecast_trainer = Trainer(\n",
        "    model=finetune_forecast_model,\n",
        "    args=finetune_forecast_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    callbacks=[early_stopping_callback],\n",
        ")\n",
        "print(\"\\n\\nFinetuning on the target data\")\n",
        "finetune_forecast_trainer.train()\n",
        "print(\"Evaluating\")\n",
        "result = finetune_forecast_trainer.evaluate(test_dataset)\n",
        "print(\"Target data full finetune result:\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2mWupcQtUY_"
      },
      "source": [
        "In this case, there is only a small improvement on the ETTh1 dataset with full fine-tuning. For other datasets there may be more substantial improvements. Let's save the model anyway."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMP3c_BUtUY_"
      },
      "outputs": [],
      "source": [
        "save_dir = f\"patchtst/electricity/model/transfer/{dataset}/model/fine_tuning/\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "finetune_forecast_trainer.save_model(save_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrFG0P-btUY_"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this blog, we presented a step-by-step guide on training `PatchTST` for tasks related to forecasting and transfer learning, demonstrating various approaches for fine-tuning. We intend to facilitate easy integration of the `PatchTST` HF model for your forecasting use cases, and we hope that this content serves as a useful resource to expedite the adoption of PatchTST. Thank you for tuning in to our blog, and we hope you find this information beneficial for your projects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HuVFD8NtUY_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}